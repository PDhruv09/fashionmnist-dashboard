# ğŸ‘• FashionMNIST Model Comparison & Explainability Dashboard

This interactive project compares deep learning models trained on the FashionMNIST dataset using a clean, modern Streamlit dashboard. It highlights key model insights such as prediction confidence, test accuracy, and misclassified examples â€” great for showcasing deep learning understanding and model evaluation skills.

ğŸ”— **Live Demo**: [Your Streamlit Link Here](https://fashionmnist-dashboard-adikhxm9kazjbmpwxdjhgt.streamlit.app/)

---

## ğŸ” Features

- Compare **MLP** and **CNN** model predictions
- Interactive visualizations:
  - ğŸ” Confusion Matrix
  - âŒ Misclassified Images
  - ğŸ” Inspect predictions on any test image
  - ğŸ“Š Side-by-side model accuracy comparison
  - ğŸ“ˆ Prediction confidence bar chart
- Responsive, toggled layout with Streamlit

---

## ğŸ§° Tech Stack

- Python & PyTorch
- Streamlit (frontend)
- Matplotlib & Seaborn
- Scikit-learn

---

## ğŸ“ Data

The data was take from an open dataset, called FashionMINST. here is the like for the repo https://github.com/zalandoresearch/fashion-mnist

---

## ğŸ“ Project Structure

```plaintext
models/       # MLP and CNN architectures
utils/        # Training, evaluation, visualization code
dashboard/    # Streamlit frontend (app.py)
assets/       # (optional) saved images, plots
requirements.txt
README.md
train_mlp.py  # MLP training script
train_cnn.py  # CNN training script
mlp.pth       # Saved trained MLP model
cnn.pth       # Saved trained CNN model
